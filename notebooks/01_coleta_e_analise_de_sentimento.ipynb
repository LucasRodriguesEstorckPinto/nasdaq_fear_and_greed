{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7817386-1c3e-4bdc-bdfa-297ef1c95e52",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c11cf38c-232c-4817-b576-2f7aef3d783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando notícias para 'NVIDIA Stock':\n",
      "Buscando página 1...\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "Página 1 não retornou resultados. Interrompendo.\n",
      "Nenhuma manchete encontrada após a busca paginada.\n"
     ]
    }
   ],
   "source": [
    "# --- Fase 1: Usando a Biblioteca GoogleNews (com Paginação) ---\n",
    "try:\n",
    "    from GoogleNews import GoogleNews\n",
    "except ImportError:\n",
    "    try:\n",
    "      from pygooglenews import GoogleNews\n",
    "    except ImportError:\n",
    "      print(\"Biblioteca GoogleNews ou pygooglenews não encontrada.\")\n",
    "      print(\"Instale com: pip3 install GoogleNews OU pip3 install pygooglenews\")\n",
    "      news_df = pd.DataFrame()\n",
    "\n",
    "import pandas as pd\n",
    "import time # Importar a biblioteca time para pausas\n",
    "\n",
    "all_results = [] # Lista para guardar resultados de todas as páginas\n",
    "\n",
    "try:\n",
    "    # --- ALTERAÇÃO AQUI: Período pode ser menor agora, ex: '7d' ou '30d' ---\n",
    "    googlenews = GoogleNews(lang='en', period='90d') # Mantemos 30d por enquanto\n",
    "    query = 'NVIDIA Stock'\n",
    "\n",
    "    # --- Loop de Paginação ---\n",
    "    print(f\"Buscando notícias para '{query}':\")\n",
    "    for page in range(1, 10): # Tenta buscar da página 1 até a 5\n",
    "        print(f\"Buscando página {page}...\")\n",
    "        googlenews.search(query)\n",
    "        googlenews.get_page(page) # Tenta ir para a página específica\n",
    "        \n",
    "        page_results = googlenews.result()\n",
    "        if not page_results: # Se não houver resultados na página, para o loop\n",
    "            print(f\"Página {page} não retornou resultados. Interrompendo.\")\n",
    "            break\n",
    "            \n",
    "        all_results.extend(page_results) # Adiciona os resultados da página à lista geral\n",
    "        time.sleep(0.5) # Pequena pausa para não sobrecarregar o Google\n",
    "\n",
    "    # --- Processamento dos Resultados Combinados ---\n",
    "    if all_results:\n",
    "        news_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Remove duplicatas baseadas no título\n",
    "        news_df = news_df.drop_duplicates(subset=['title'])\n",
    "\n",
    "        if 'title' in news_df.columns:\n",
    "            news_df = news_df[['title']].rename(columns={'title': 'Title'})\n",
    "            print(f\"\\nEncontradas {len(news_df)} manchetes únicas após buscar {page-1 if page > 1 else 1} página(s).\")\n",
    "            display(news_df.head())\n",
    "        else:\n",
    "            print(\"Não foram encontradas manchetes ou a coluna 'title'.\")\n",
    "            news_df = pd.DataFrame()\n",
    "    else:\n",
    "        print(\"Nenhuma manchete encontrada após a busca paginada.\")\n",
    "        news_df = pd.DataFrame()\n",
    "\n",
    "except NameError:\n",
    "    pass\n",
    "except AttributeError:\n",
    "    print(\"\\nERRO: A biblioteca instalada pode não ter o método 'get_page()'.\")\n",
    "    print(\"Verifique a documentação da versão que você instalou.\")\n",
    "    news_df = pd.DataFrame() # Garante que news_df exista\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro durante a busca paginada: {e}\")\n",
    "    news_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8de1281d-889a-4a8d-9ee5-99cb17d5564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame com as pontuações de sentimento:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nvidia leads $260 mn round in IIT-Madras incub...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI Heavyweight Nvidia Leads 15 Hot Stocks Onto...</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Líderes em IA e dados NVIDIA, AMD, Snowflake e...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVIDIA Corporation (NVDA): A Bull Case Theory</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Like it or not, we’re all living in the AI eco...</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>The 3 largest individual stock holdings in my ...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Is There Still an Opportunity for Investors Af...</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Intel’s Big Investors Set The Stage For A Make...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>2 Brilliant Growth Stocks to Buy Now and Hold ...</td>\n",
       "      <td>0.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Think You Missed the Boat on Nvidia? Here's th...</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  Sentiment\n",
       "0    Nvidia leads $260 mn round in IIT-Madras incub...     0.0000\n",
       "1    AI Heavyweight Nvidia Leads 15 Hot Stocks Onto...     0.6369\n",
       "2    Líderes em IA e dados NVIDIA, AMD, Snowflake e...     0.0000\n",
       "3        NVIDIA Corporation (NVDA): A Bull Case Theory     0.0000\n",
       "4    Like it or not, we’re all living in the AI eco...     0.3612\n",
       "..                                                 ...        ...\n",
       "895  The 3 largest individual stock holdings in my ...     0.0000\n",
       "896  Is There Still an Opportunity for Investors Af...     0.4215\n",
       "897  Intel’s Big Investors Set The Stage For A Make...     0.0000\n",
       "898  2 Brilliant Growth Stocks to Buy Now and Hold ...     0.7506\n",
       "899  Think You Missed the Boat on Nvidia? Here's th...    -0.2960\n",
       "\n",
       "[85 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Fase 2: Análise de Sentimento com VADER ---\n",
    "\n",
    "# Importando a ferramenta de análise de sentimento\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd # Reimportar pandas caso necessário\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def calculate_sentiment(text):\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    return vs['compound']\n",
    "\n",
    "if not news_df.empty:\n",
    "    news_df['Sentiment'] = news_df['Title'].apply(calculate_sentiment)\n",
    "\n",
    "    print(\"\\nDataFrame com as pontuações de sentimento:\")\n",
    "    display(news_df)\n",
    "else:\n",
    "    print(\"\\nDataFrame de notícias está vazio. Não foi possível calcular o sentimento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f08f34c-ff48-4b9a-a00d-be3995cb3a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando dados da NVDA de 2025-07-14 até 2025-10-22...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/3fck38_57j918mwlyxrxlxnh0000gn/T/ipykernel_10976/2842623177.py:13: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  nvda_df = yf.download(ticker_stock, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame com os retornos diários da NVDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Daily_Return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-07-16</th>\n",
       "      <td>0.003925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-17</th>\n",
       "      <td>0.009512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-18</th>\n",
       "      <td>-0.003410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-21</th>\n",
       "      <td>-0.005974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22</th>\n",
       "      <td>-0.025382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price      Daily_Return\n",
       "Ticker                 \n",
       "Date                   \n",
       "2025-07-16     0.003925\n",
       "2025-07-17     0.009512\n",
       "2025-07-18    -0.003410\n",
       "2025-07-21    -0.005974\n",
       "2025-07-22    -0.025382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Fase 3: Coleta dos Dados de Mercado (NVDA) - CORRIGIDO ---\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# --- Passagem 1: Baixando os dados da NVDA ---\n",
    "ticker_stock = 'NVDA'\n",
    "end_date = pd.Timestamp.today()\n",
    "start_date = end_date - pd.Timedelta(days=100)\n",
    "\n",
    "print(f\"Buscando dados da {ticker_stock} de {start_date.date()} até {end_date.date()}...\")\n",
    "# yfinance já ajusta os preços por padrão (auto_adjust=True)\n",
    "nvda_df = yf.download(ticker_stock, start=start_date, end=end_date)\n",
    "\n",
    "# --- Passagem 2: Calculando os Retornos Diários (usando 'Close') ---\n",
    "# Como 'Close' já está ajustado, usamos ele para calcular o retorno\n",
    "nvda_df['Daily_Return'] = nvda_df['Close'].pct_change() # <-- CORREÇÃO AQUI\n",
    "\n",
    "# --- Passagem 3: Preparando o DataFrame de Retornos ---\n",
    "nvda_returns = nvda_df[['Daily_Return']].dropna()\n",
    "nvda_returns.index.name = 'Date'\n",
    "\n",
    "print(\"\\nDataFrame com os retornos diários da NVDA:\")\n",
    "display(nvda_returns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fa0ad4a-cd69-4812-8dac-b6ad16206a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rebuscando notícias para obter datas...\n",
      "HTTP Error 429: Too Many Requests\n",
      "HTTP Error 429: Too Many Requests\n",
      "Nenhuma notícia encontrada para processar.\n"
     ]
    }
   ],
   "source": [
    "#Fase 4: Agregando Sentimento e Juntando Dados\n",
    "try:\n",
    "    try:\n",
    "        from GoogleNews import GoogleNews\n",
    "    except ImportError:\n",
    "        from pygooglenews import GoogleNews\n",
    "    import time\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "    googlenews = GoogleNews(lang='en', period='90d')\n",
    "    query = 'NVIDIA Stock'\n",
    "    all_results = []\n",
    "    print(\"\\nRebuscando notícias para obter datas...\")\n",
    "    for page in range(1, 10):\n",
    "        googlenews.search(query)\n",
    "        googlenews.get_page(page)\n",
    "        page_results = googlenews.result(sort=True)\n",
    "        if not page_results: break\n",
    "        all_results.extend(page_results)\n",
    "        time.sleep(1)\n",
    "\n",
    "    if all_results:\n",
    "        news_df_full = pd.DataFrame(all_results)\n",
    "        news_df_full = news_df_full.drop_duplicates(subset=['title'])\n",
    "        print(f\"Total de {len(news_df_full)} notícias com detalhes.\")\n",
    "\n",
    "        date_column_name = 'datetime' # <- VERIFIQUE ESTE NOME!\n",
    "\n",
    "        if date_column_name not in news_df_full.columns:\n",
    "            print(f\"\\nERRO CRÍTICO: Coluna de data '{date_column_name}' não encontrada!\")\n",
    "            print(\"Verifique as colunas disponíveis:\", news_df_full.columns)\n",
    "            raise KeyError(f\"Coluna '{date_column_name}' não encontrada.\")\n",
    "\n",
    "        news_df_full['Date'] = pd.to_datetime(news_df_full[date_column_name]).dt.date\n",
    "        news_df_full['Date'] = pd.to_datetime(news_df_full['Date'])\n",
    "\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        news_df_full['Sentiment'] = news_df_full['title'].apply(calculate_sentiment)\n",
    "\n",
    "        # --- Passagem 2: Calcular o Sentimento Médio por Dia ---\n",
    "        daily_sentiment = news_df_full.groupby('Date')['Sentiment'].mean().reset_index()\n",
    "        print(\"\\nSentimento médio por dia:\")\n",
    "        display(daily_sentiment.head())\n",
    "\n",
    "        # Garante que nvda_returns tenha um índice simples e 'Date' como coluna\n",
    "        if isinstance(nvda_returns.index, pd.MultiIndex):\n",
    "             print(\"Índice de nvda_returns é MultiIndex, resetando...\")\n",
    "             nvda_returns_flat = nvda_returns.reset_index()\n",
    "        elif nvda_returns.index.name == 'Date':\n",
    "             nvda_returns_flat = nvda_returns.reset_index()\n",
    "        else:\n",
    "            # Se já for índice simples sem nome 'Date', apenas copia\n",
    "            nvda_returns_flat = nvda_returns.reset_index() # Resetar de qualquer forma é seguro\n",
    "\n",
    "        # Garante que daily_sentiment tenha um índice simples\n",
    "        daily_sentiment_flat = daily_sentiment.reset_index(drop=True) # drop=True evita criar coluna 'index'\n",
    "\n",
    "        # Verifica os nomes das colunas de data (devem ser 'Date' em ambos)\n",
    "        print(\"\\nColunas antes do merge:\")\n",
    "        print(\"Retornos:\", nvda_returns_flat.columns)\n",
    "        print(\"Sentimento:\", daily_sentiment_flat.columns)\n",
    "\n",
    "        # Garante que ambas as colunas 'Date' sejam do tipo datetime\n",
    "        nvda_returns_flat['Date'] = pd.to_datetime(nvda_returns_flat['Date'])\n",
    "        daily_sentiment_flat['Date'] = pd.to_datetime(daily_sentiment_flat['Date'])\n",
    "\n",
    "\n",
    "        print(\"\\nTentando fazer o merge...\")\n",
    "        merged_df = pd.merge(nvda_returns_flat, daily_sentiment_flat, on='Date', how='left')\n",
    "        print(\"Merge bem-sucedido!\")\n",
    "\n",
    "        merged_df['Sentiment'] = merged_df['Sentiment'].fillna(0)\n",
    "\n",
    "        print(\"\\nDataFrame final combinado (Retornos e Sentimento):\")\n",
    "        display(merged_df.head())\n",
    "\n",
    "    else:\n",
    "        print(\"Nenhuma notícia encontrada para processar.\")\n",
    "        merged_df = pd.DataFrame()\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"Erro: Bibliotecas não importadas ou variável não definida. Detalhe: {e}\")\n",
    "     merged_df = pd.DataFrame()\n",
    "except KeyError as e:\n",
    "     print(f\"Erro CRÍTICO ao processar DataFrame: {e}. Verifique nomes de colunas.\")\n",
    "     merged_df = pd.DataFrame()\n",
    "except Exception as e:\n",
    "     print(f\"Ocorreu um erro inesperado: {e}\")\n",
    "     merged_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9bb57-2847-47ef-bc38-474d6c9680f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
